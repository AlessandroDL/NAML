{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8320671,"sourceType":"datasetVersion","datasetId":4942459}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport warnings\nimport logging\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\nfrom sklearn.metrics import mean_squared_error, accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.utils import shuffle\nfrom skimage.color import rgb2gray\nfrom glob import glob\nseed = 100\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"1K4HR7Edknzc","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-04T14:44:59.480560Z","iopub.execute_input":"2024-09-04T14:44:59.480998Z","iopub.status.idle":"2024-09-04T14:44:59.490093Z","shell.execute_reply.started":"2024-09-04T14:44:59.480955Z","shell.execute_reply":"2024-09-04T14:44:59.488877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#settings\nplt.rc('font', size=16)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\n\nnp.random.seed(seed)\n\ntf.autograph.set_verbosity(0)\ntf.get_logger().setLevel(logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\nprint(tf.__version__)","metadata":{"id":"EuVZoclQknzd","outputId":"3887c480-f591-4f56-a60d-2a0261ccf729","execution":{"iopub.status.busy":"2024-09-04T14:44:59.491998Z","iopub.execute_input":"2024-09-04T14:44:59.492727Z","iopub.status.idle":"2024-09-04T14:44:59.536737Z","shell.execute_reply.started":"2024-09-04T14:44:59.492695Z","shell.execute_reply":"2024-09-04T14:44:59.535776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset loading","metadata":{}},{"cell_type":"code","source":"#Starting from a prepocessed dataset, where each audio is already been cut in 11 parts, this code loads each part in order.\ngenre_dict = {\"blues\":0,\"classical\":1,\"country\":2,\"disco\":3,\"hiphop\":4,\"jazz\":5,\"metal\":6,\"pop\":7,\"reggae\":8,\"rock\":9}\npath_image_files = \"/kaggle/input/mel_spectrogram_imgs/\"\ngenres = list(genre_dict.keys())\n\nfor genre in genres:\n    print(\"\\t\",genre)\n    path = path_image_files + genre + \"/\" + genre + \"_\"\n    if genre == \"jazz\":\n        for i in range(1089):\n            inputs.append(rgb2gray(mpimg.imread(path + str(i) +\".png\")[:,:,0:3]))\n            labels.append(genre)\n    else:\n        for i in range(1100):\n            inputs.append(rgb2gray(mpimg.imread(path + str(i) +\".png\")[:,:,0:3]))\n            labels.append(genre)\n\n    print(len(inputs))\n    print(len(labels))","metadata":{"id":"BbRXUnMLknze","outputId":"6a3d2d06-bb10-4a81-8104-63c744c02bf7","execution":{"iopub.status.busy":"2024-09-04T14:44:59.538867Z","iopub.execute_input":"2024-09-04T14:44:59.539719Z","iopub.status.idle":"2024-09-04T14:45:36.559948Z","shell.execute_reply.started":"2024-09-04T14:44:59.539684Z","shell.execute_reply":"2024-09-04T14:45:36.559012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = np.asarray(inputs)\nlabels = np.asarray(labels)\n\n#For the prediction, the labels are turned into the one-hot encoder notation\nenc = OneHotEncoder(sparse_output = False)\nlabels = labels.reshape(-1, 1)\nlabels = enc.fit_transform(labels)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:45:36.573668Z","iopub.execute_input":"2024-09-04T14:45:36.573910Z","iopub.status.idle":"2024-09-04T14:45:37.516854Z","shell.execute_reply.started":"2024-09-04T14:45:36.573888Z","shell.execute_reply":"2024-09-04T14:45:37.515806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(labels.shape)\nprint(inputs.shape)\ninput_shape = inputs.shape[1:]\noutput_shape = labels.shape[1:]\n\n#This vector contains the indices of the first slice of each audio. Since audios are loaded in order, we use them as reference.\noriginal_indices = np.arange(0, inputs.shape[0], 11)\noriginal_labels = labels[original_indices]\nprint(original_labels.shape)\nprint(original_indices.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:45:37.518163Z","iopub.execute_input":"2024-09-04T14:45:37.518940Z","iopub.status.idle":"2024-09-04T14:45:37.527563Z","shell.execute_reply.started":"2024-09-04T14:45:37.518903Z","shell.execute_reply":"2024-09-04T14:45:37.526661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Network","metadata":{"id":"hy2U38xhq-4V"}},{"cell_type":"code","source":"#This is the RGLU block.\ndef RGLU(x, filters, name):\n    x1 = tfkl.Conv1D(filters=filters, kernel_size=3, strides=1, padding=\"same\", data_format=\"channels_first\", name=name)(x)\n    x2 = tfkl.Conv1D(filters=filters, kernel_size=3, strides=1, padding=\"same\", data_format=\"channels_first\", name=name + 'B')(x)\n    x1 = tfkl.BatchNormalization()(x1)\n    x2 = tfkl.BatchNormalization()(x2)\n    x1 = tfk.activations.sigmoid(x1)\n    y = tfkl.Multiply()([x1,x2])\n    #This if perform the add operation when the input and output size match.\n    if x.shape == y.shape:\n        y = tfkl.Add()([x, y])\n    return y","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:57:03.420546Z","iopub.execute_input":"2024-09-04T14:57:03.421271Z","iopub.status.idle":"2024-09-04T14:57:03.427583Z","shell.execute_reply.started":"2024-09-04T14:57:03.421217Z","shell.execute_reply":"2024-09-04T14:57:03.426657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This class implements a positional encoding layer.\nclass PositionalEncoding(tfkl.Layer):\n    def __init__(self, sequence_length, d_model):\n        super(PositionalEncoding, self).__init__()\n        self.pos_encoding = self.positional_encoding(sequence_length, d_model)\n    \n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'sequence_length': self.pos_encoding.shape[1],\n            'd_model': self.pos_encoding.shape[2],\n        })\n        return config\n\n    def positional_encoding(self, sequence_length, d_model):\n        angle_rads = self.get_angles(np.arange(sequence_length)[:, np.newaxis],\n                                     np.arange(d_model)[np.newaxis, :],\n                                     d_model)\n        \n        # apply sin to even indices in the array; 2i\n        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n        \n        # apply cos to odd indices in the array; 2i+1\n        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n        \n        pos_encoding = angle_rads[np.newaxis, ...]\n        return tf.cast(pos_encoding, dtype=tf.float32)\n    \n    def get_angles(self, pos, i, d_model):\n        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n        return pos * angle_rates\n    \n    def call(self, inputs):\n        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:45:37.538527Z","iopub.execute_input":"2024-09-04T14:45:37.538791Z","iopub.status.idle":"2024-09-04T14:45:37.549624Z","shell.execute_reply.started":"2024-09-04T14:45:37.538767Z","shell.execute_reply":"2024-09-04T14:45:37.548824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is the transformer block, formed with the positional encoding, multi-head self-attention and the final \n#feed-forward layers.\ndef transformer_encoder(x, num_heads, ff_dim, dropout_rate):\n    \n    sequence_length = 256\n    d_model = 10  # Embedding dimension\n    \n    x = PositionalEncoding(sequence_length, d_model)(x)\n    \n    # Multihead attention\n    attention_output = tfkl.MultiHeadAttention(num_heads=num_heads, key_dim=x.shape[-1])(x, x)\n    attention_output = tfkl.Dropout(dropout_rate)(attention_output)\n    x = tfkl.LayerNormalization(epsilon=1e-6)(x + attention_output)\n    \n    #Feed-forward\n    y = tfkl.Dense(units=ff_dim, activation = 'relu')(x)\n    y = tfkl.Dropout(dropout_rate)(y)\n    y = tfkl.Dense(units=x.shape[-1])(y)\n    y = tfkl.Dropout(dropout_rate)(y)\n    x = tfkl.LayerNormalization(epsilon=1e-6)(x + y)\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:45:37.556004Z","iopub.execute_input":"2024-09-04T14:45:37.556337Z","iopub.status.idle":"2024-09-04T14:45:37.563219Z","shell.execute_reply.started":"2024-09-04T14:45:37.556313Z","shell.execute_reply":"2024-09-04T14:45:37.562243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build the actual model\ndef build_model(input_shape=input_shape, output_shape=output_shape):\n    tf.random.set_seed(seed)\n\n    input_layer = tfkl.Input(shape=input_shape, name='Input')\n    filters = 64\n    \n    #This is the convolutional part of the model.\n    x = tfkl.Conv1D(filters=filters, kernel_size=3, strides=1, padding=\"same\", data_format=\"channels_first\", name='conv')(input_layer)\n    for i in range(5):\n        x = RGLU(x, filters, 'conv_' + str(i))\n        #These ifs are used to increase the filters number.\n        if (i == 1 or i ==3):\n            filters += 64\n        if (i==3):\n            filters += 64\n        x = RGLU(x, filters, 'conv2_' + str(i))\n        x = tfkl.MaxPooling1D(pool_size=2, strides=2, padding=\"valid\", data_format=\"channels_first\",name = 'mp' + str(i))(x)\n    \n    #This is the encoder part, implemented by just calling the transformer block.\n    x = transformer_encoder(x, 8, 2048, 0.1)\n    \n    #This is the decoder part, where the code performs both GAP and GMP, concatenates the results and then performs the prediction.\n    x1 = tfkl.GlobalAveragePooling1D(data_format='channels_first')(x)\n    x2 = tfkl.GlobalMaxPooling1D(data_format='channels_first')(x)\n    x = tfkl.Concatenate()([x1, x2])\n    \n    x = tfkl.Dense(units = 200, activation='relu', name = 'dense1')(x)\n    x = tfkl.Dropout(0.2)(x)\n    x = tfkl.Dense(units = 100, activation='relu', name = 'dense2')(x)\n    x = tfkl.Dropout(0.2)(x)\n    output_layer = tfkl.Dense(units=10, activation='softmax',name='Output')(x)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='CNN')\n\n    # Compile the model using Categorical Crossentropy as loss, Adam as learning rate update technique and accuracy as the main metrics.\n    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n\n    # Return the model\n    return model","metadata":{"id":"D7ao-7iMrCN-","execution":{"iopub.status.busy":"2024-09-04T14:57:09.497647Z","iopub.execute_input":"2024-09-04T14:57:09.497996Z","iopub.status.idle":"2024-09-04T14:57:09.510150Z","shell.execute_reply.started":"2024-09-04T14:57:09.497967Z","shell.execute_reply":"2024-09-04T14:57:09.509209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the model\nmodel = build_model()\nmodel.summary()\ntfk.utils.plot_model(model, expand_nested=True, show_shapes=True)","metadata":{"id":"yqq5StERsJJ3","outputId":"e194b7a5-f9e7-4960-c4cb-444430eeccd7","execution":{"iopub.status.busy":"2024-09-04T14:57:14.495585Z","iopub.execute_input":"2024-09-04T14:57:14.496240Z","iopub.status.idle":"2024-09-04T14:57:19.860688Z","shell.execute_reply.started":"2024-09-04T14:57:14.496206Z","shell.execute_reply":"2024-09-04T14:57:19.859410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and Testing","metadata":{}},{"cell_type":"code","source":"#This class implements k_fold keeping the distribution of each class equal through each fold. \ndef stratified_multilabel_kfold(X, y, n_splits=10, shuffle_data=True, random_state=None):\n    \"\"\"\n    Stratified K-Fold cross-validation for multilabel data with 80/10/10 train/validation/test split.\n    \n    Parameters:\n    - X: Feature matrix.\n    - y: Multilabel binary matrix (samples x labels).\n    - n_splits: Number of folds (default is 10).\n    - shuffle_data: Whether to shuffle the data before splitting.\n    - random_state: Seed for shuffling (if applicable).\n\n    Returns:\n    - folds: List of (train_index, val_index, test_index) tuples for each fold.\n    \"\"\"\n    if shuffle_data:\n        X, y = shuffle(X, y, random_state=random_state)\n    \n    n_samples, n_labels = y.shape\n    \n    # Desired sizes for train, validation, and test sets\n    n_test = n_val = n_samples // n_splits\n    n_train = n_samples - n_test - n_val\n\n    fold_indices = [[] for _ in range(n_splits)]\n    label_counts_per_fold = [np.zeros(n_labels) for _ in range(n_splits)]\n    \n    # Get the number of labels per sample\n    samples_with_counts = [(i, y[i].sum()) for i in range(n_samples)]\n    samples_with_counts = sorted(samples_with_counts, key=lambda x: x[1], reverse=True)\n\n    # Assign each sample to the fold with the least corresponding labels\n    for sample_index, _ in samples_with_counts:\n        min_fold = np.argmin([label_counts_per_fold[i].sum() for i in range(n_splits)])\n        fold_indices[min_fold].append(sample_index)\n        label_counts_per_fold[min_fold] += y[sample_index]\n\n    # Create the train/validation/test splits\n    folds = []\n    for i in range(n_splits):\n        test_indices = fold_indices[i]\n        remaining_indices = [idx for j in range(n_splits) if j != i for idx in fold_indices[j]]\n        \n        # Shuffle remaining indices to randomize the split\n        if shuffle_data:\n            np.random.seed(random_state)\n            np.random.shuffle(remaining_indices)\n        \n        val_indices = remaining_indices[:n_val]\n        train_indices = remaining_indices[n_val:n_val + n_train]\n        \n        folds.append((train_indices, val_indices, test_indices))\n\n    return folds","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:57:34.082988Z","iopub.execute_input":"2024-09-04T14:57:34.083341Z","iopub.status.idle":"2024-09-04T14:57:34.094617Z","shell.execute_reply.started":"2024-09-04T14:57:34.083313Z","shell.execute_reply":"2024-09-04T14:57:34.093581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_folds = stratified_multilabel_kfold(inputs, labels, random_state=42)\n\naccuracies = []\nprecisions = []\nrecalls = []\nf1_scores = []\n\n#This is the training part of the model.\nfor fold, (train_indices, val_indices, test_indices) in enumerate(custom_folds):\n    \n    X_train, X_val, X_test = inputs[train_indices], inputs[val_indices], inputs[test_indices]\n    y_train, y_val, y_test = labels[train_indices], labels[val_indices], labels[test_indices]\n    \n    print(f\"Fold {fold + 1}\")\n    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n    print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n    print()\n\n    #The model is built every time in order to reinitialize weights for each fold.\n    model = build_model()\n    #We used early stopping technique to reduce overfitting.\n    early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=80, mode='auto', restore_best_weights=True)\n    \n    # Train the model and save its history\n    history = model.fit(\n        x=X_train,\n        y=y_train,\n        batch_size=32,\n        epochs=500,\n        validation_data=(X_val, y_val),\n        callbacks=[early_stopping]\n    ).history\n    \n    # Predict the test set\n    y_pred = model.predict(X_test)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    y_true = np.argmax(y_test, axis=1)\n    \n    # Calculate metrics for this fold\n    accuracies.append(accuracy_score(y_true, y_pred_classes))\n    precisions.append(precision_score(y_true, y_pred_classes, average='weighted'))\n    recalls.append(recall_score(y_true, y_pred_classes, average='weighted'))\n    f1_scores.append(f1_score(y_true, y_pred_classes, average='weighted'))","metadata":{"id":"Zt63KogYx68l","outputId":"d5e9cecc-f634-4f2a-8435-07b897f25693","execution":{"iopub.status.busy":"2024-09-04T14:57:41.481433Z","iopub.execute_input":"2024-09-04T14:57:41.481723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The final result is computed by averaging metrics through each fold.\nmean_accuracy = np.mean(accuracies)\nmean_precision = np.mean(precisions)\nmean_recall = np.mean(recalls)\nmean_f1_score = np.mean(f1_scores)\n\nprint(f'Mean Accuracy: {mean_accuracy:.4f}')\nprint(f'Mean Precision: {mean_precision:.4f}')\nprint(f'Mean Recall: {mean_recall:.4f}')\nprint(f'Mean F1-Score: {mean_f1_score:.4f}')","metadata":{"id":"jskacf7qQlXr","outputId":"c4c98e72-b55e-4644-ae54-e86221fc2b5f","execution":{"iopub.status.busy":"2024-09-04T14:54:03.814004Z","iopub.status.idle":"2024-09-04T14:54:03.814362Z","shell.execute_reply.started":"2024-09-04T14:54:03.814181Z","shell.execute_reply":"2024-09-04T14:54:03.814208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is the plot of each metrics through the folds.\nfolds = range(1, 11)\n\nplt.figure(figsize=(10, 6))\n\nplt.plot(folds, accuracies, marker='o', label='Accuracy')\nplt.plot(folds, precisions, marker='o', label='Precision')\nplt.plot(folds, recalls, marker='o', label='Recall')\nplt.plot(folds, f1_scores, marker='o', label='F1-Score')\nplt.title('Metrics Across 10 Folds')\nplt.xlabel('Fold')\nplt.ylabel('Score')\nplt.xticks(folds)\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"id":"qGMgBYA8UE3s","outputId":"81810c83-c039-4418-b3df-70d4655271a6","execution":{"iopub.status.busy":"2024-09-04T14:54:03.815229Z","iopub.status.idle":"2024-09-04T14:54:03.815538Z","shell.execute_reply.started":"2024-09-04T14:54:03.815379Z","shell.execute_reply":"2024-09-04T14:54:03.815392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Voting based testing","metadata":{}},{"cell_type":"code","source":"#The 10 folds are created using the indices of the first part of each code. \ncustom_folds = stratified_multilabel_kfold(original_indices, original_labels, random_state=42)\n\naccuracies = []\nprecisions = []\nrecalls = []\nf1_scores = []\n\nfor fold, (train_indices, val_indices, test_indices) in enumerate(custom_folds):\n    \n    X_train = list()\n    X_val = list()\n    X_test = list()\n    y_train = list()\n    y_val = list()\n    y_test = list()\n    \n    #Each set for each fold is composed by slices belonging to the same audio. \n    for i in train_indices:\n        for j in range(11):\n            X_train.append(inputs[original_indices[i] + j])\n            y_train.append(labels[original_indices[i] + j])\n    for i in val_indices:\n        for j in range(11):\n            X_val.append(inputs[original_indices[i] + j])\n            y_val.append(labels[original_indices[i] + j])\n    for i in test_indices:\n        for j in range(11):\n            X_test.append(inputs[original_indices[i] + j])\n    y_test = original_labels[test_indices]\n    \n    X_train = np.asarray(X_train)\n    y_train = np.asarray(y_train)\n    X_val = np.asarray(X_val)\n    y_val = np.asarray(y_val)\n    X_test = np.asarray(X_test)\n    \n    print(f\"Fold {fold + 1}\")\n    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n    print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n    print()\n    \n    model = build_model()\n    early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, mode='auto', restore_best_weights=True)\n    #We shuffled the training set and validation set to introduce a little bit of stochasticity\n    X_train, y_train = shuffle(X_train, y_train, random_state=0)\n    X_val, y_val = shuffle(X_val, y_val, random_state=0)\n    \n    # Train the model and save its history\n    history = model.fit(\n        x=X_train,\n        y=y_train,\n        batch_size=32,\n        epochs=700,\n        validation_data=(X_val, y_val),\n        callbacks=[early_stopping]\n    ).history\n    \n    # Predict the test set\n    y_pred_temp = model.predict(X_test)\n    y_true = np.argmax(y_test, axis=1)\n    y_pred = list()\n    \n    # Perform sum along the columns to count votes for each class\n    for i in range(0, y_pred_temp.shape[0], 11):\n        votes = np.sum(y_pred_temp[i:i+11], axis=0)\n\n        # Identify the class with the maximum votes\n        max_vote_class = np.argmax(votes)\n        \n        y_pred.append(max_vote_class)\n        \n    y_pred_classes = np.asarray(y_pred)\n    \n    # Calculate metrics for this fold\n    accuracies.append(accuracy_score(y_true, y_pred_classes))\n    precisions.append(precision_score(y_true, y_pred_classes, average='weighted'))\n    recalls.append(recall_score(y_true, y_pred_classes, average='weighted'))\n    f1_scores.append(f1_score(y_true, y_pred_classes, average='weighted'))\n    print(accuracy_score(y_true, y_pred_classes))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is the plot of each metrics through the folds.\nfolds = range(1, 11)\n\nplt.figure(figsize=(10, 6))\n\nplt.plot(folds, accuracies, marker='o', label='Accuracy')\nplt.plot(folds, precisions, marker='o', label='Precision')\nplt.plot(folds, recalls, marker='o', label='Recall')\nplt.plot(folds, f1_scores, marker='o', label='F1-Score')\nplt.title('Metrics Across 10 Folds')\nplt.xlabel('Fold')\nplt.ylabel('Score')\nplt.xticks(folds)\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}